{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LwPcaFWAqoh"
      },
      "source": [
        "# BÀI THỰC HÀNH 2: MẠNG NEURAL TÍCH CHẬP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcmydxzEBA4D",
        "outputId": "251911a9-cd40-489f-93ff-53efbf15780f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Kết nối Google Colab với Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6auZ3HdxAqpf"
      },
      "source": [
        "<b>Hướng dẫn nộp bài:</b> Các bạn commit và push code lên github, sử dụng file txt đặt tên theo cú pháp <MSSV>.txt chứa đường link dẫn đến github của bài thực hành và nộp file txt này tên courses.\n",
        "\n",
        "Bộ dữ liệu sử dụng: [MNIST dataset](https://git-disl.github.io/GTDLBench/datasets/mnist_datasets/) (bài 1) và [VinaFood21 dataset](https://arxiv.org/abs/2108.02929) (các bài còn lại).\n",
        "\n",
        "Link download: https://drive.google.com/file/d/1UpZOf0XlwvB4rKpyZ35iwTA8oWHqDBbR/view?usp=share_link."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-RV1ij0Aqpi"
      },
      "source": [
        "### Bài 1: Xây dựng mô hình LeNet. Huấn luyện và đánh giá mô hình LeNet trên 4 độ đo precision, recall và F1-macro (sử dụng Adam làm optimizer)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Gyf9hfbFAqpj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlfTtwrQAqpm",
        "outputId": "dcb126e5-dbbe-4e2a-c055-a2d0aaa5e359"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tạo DataLoader từ file local thành công!\n",
            "Sử dụng thiết bị: cpu\n"
          ]
        }
      ],
      "source": [
        "def load_mnist(images_path, labels_path):\n",
        "    \"\"\"Hàm đọc file .ubyte của MNIST.\"\"\"\n",
        "    with open(labels_path, 'rb') as lbpath:\n",
        "        lbpath.read(8)  # Bỏ qua magic number và số lượng items\n",
        "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
        "\n",
        "    with open(images_path, 'rb') as imgpath:\n",
        "        imgpath.read(16)  # Bỏ qua magic number, số lượng ảnh, số hàng, số cột\n",
        "        # Đọc dữ liệu ảnh và reshape thành (số lượng ảnh, 784)\n",
        "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "class MNISTDataset(Dataset):\n",
        "    \"\"\"Custom Dataset cho MNIST.\"\"\"\n",
        "    def __init__(self, images_path, labels_path, transform=None):\n",
        "        self.images, self.labels = load_mnist(images_path, labels_path)\n",
        "        self.transform = transform\n",
        "\n",
        "        # Chuyển đổi sang tensor và chuẩn hóa ảnh\n",
        "        self.images = torch.tensor(self.images, dtype=torch.float32) / 255.0\n",
        "        self.labels = torch.tensor(self.labels, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Reshape ảnh thành (1, 28, 28) cho mạng CNN\n",
        "        image = self.images[idx].view(1, 28, 28)\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "def get_mnist_loaders(batch_size=64):\n",
        "    \"\"\"Hàm tạo DataLoader từ các file local.\"\"\"\n",
        "    base_path = '/content/drive/MyDrive/Colab_Notebooks/DS201/LAB_2'\n",
        "    train_images_path = os.path.join(base_path, 'train-images.idx3-ubyte')\n",
        "    train_labels_path = os.path.join(base_path, 'train-labels.idx1-ubyte')\n",
        "    test_images_path = os.path.join(base_path, 't10k-images.idx3-ubyte')\n",
        "    test_labels_path = os.path.join(base_path, 't10k-labels.idx1-ubyte')\n",
        "\n",
        "    # Kiểm tra sự tồn tại của file\n",
        "    for path in [train_images_path, train_labels_path, test_images_path, test_labels_path]:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Không tìm thấy file: {path}. Vui lòng kiểm tra lại cấu trúc thư mục.\")\n",
        "\n",
        "    train_dataset = MNISTDataset(images_path=train_images_path, labels_path=train_labels_path)\n",
        "    test_dataset = MNISTDataset(images_path=test_images_path, labels_path=test_labels_path)\n",
        "\n",
        "    train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "# Lấy loaders\n",
        "train_loader, test_loader = get_mnist_loaders(batch_size=64)\n",
        "print(\"Tạo DataLoader từ file local thành công!\")\n",
        "\n",
        "\n",
        "# Kiểm tra thiết bị (sử dụng GPU nếu có)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Sử dụng thiết bị: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHZdQLqFAqpq",
        "outputId": "2938d773-c884-404c-bb3b-9d2a3f3b0470"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LeNet(\n",
            "  (sigmoid): Sigmoid()\n",
            "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "  (pool1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
            "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1, padding=2)\n",
        "        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n",
        "        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.sigmoid(self.conv1(x)))\n",
        "        x = self.pool2(self.sigmoid(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = self.sigmoid(self.fc1(x))\n",
        "        x = self.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "model = LeNet().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrqp3kNMAqps"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8m2eaFQ0Aqpu",
        "outputId": "dbb5a907-276f-4701-902d-2a02de1d4dcc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]: 100%|██████████| 938/938 [00:16<00:00, 55.18it/s, loss=0.193]\n",
            "Epoch [2/10]: 100%|██████████| 938/938 [00:21<00:00, 44.06it/s, loss=0.0912]\n",
            "Epoch [3/10]: 100%|██████████| 938/938 [00:17<00:00, 53.25it/s, loss=0.243]\n",
            "Epoch [4/10]: 100%|██████████| 938/938 [00:17<00:00, 53.32it/s, loss=0.0631]\n",
            "Epoch [5/10]: 100%|██████████| 938/938 [00:17<00:00, 54.61it/s, loss=0.0957]\n",
            "Epoch [6/10]: 100%|██████████| 938/938 [00:17<00:00, 53.94it/s, loss=0.00847]\n",
            "Epoch [7/10]: 100%|██████████| 938/938 [00:16<00:00, 55.19it/s, loss=0.0294]\n",
            "Epoch [8/10]: 100%|██████████| 938/938 [00:16<00:00, 57.30it/s, loss=0.121]\n",
            "Epoch [9/10]: 100%|██████████| 938/938 [00:17<00:00, 54.38it/s, loss=0.0608]\n",
            "Epoch [10/10]: 100%|██████████| 938/938 [00:18<00:00, 51.73it/s, loss=0.0422]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hoàn thành quá trình huấn luyện!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "    loop = tqdm(train_loader, total=len(train_loader), leave=True)\n",
        "    for images, labels in loop:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "print(\"Hoàn thành quá trình huấn luyện!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujTIXfaiDkWd",
        "outputId": "c073f64b-6c0f-41bc-ad17-8f6be5efbb0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Kết quả đánh giá trên tập test ---\n",
            "Accuracy: 0.9831\n",
            "Precision (macro): 0.9832\n",
            "Recall (macro): 0.9830\n",
            "F1-score (macro): 0.9830\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "all_labels = []\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "all_labels = np.array(all_labels)\n",
        "all_preds = np.array(all_preds)\n",
        "\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "print(\"\\n--- Kết quả đánh giá trên tập test ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (macro): {precision:.4f}\")\n",
        "print(f\"Recall (macro): {recall:.4f}\")\n",
        "print(f\"F1-score (macro): {f1:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWriWCcHAqpv"
      },
      "source": [
        "### Bài 2: Xây dựng mô hình GoogLeNet. Huấn luyện và đánh giá mô hình GoogLeNet trên 4 độ đo precision, recall và F1 (sử dụng Adam làm optimizer). Lưu ý lớp Convolution đầu tiên có padding là 3, các lớp Max Pooling đều bật chế độ ceil_mode (`ceil_mode=True`).\n",
        "\n",
        "**Inception Blocks**\n",
        "\n",
        "**GoogLeNet (Multi-branch Network)**\n",
        "\n",
        "\n",
        "**GoogLeNet Parameters**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTKDbpdt9Gh7",
        "outputId": "4547db10-056e-42b5-d182-18a180a2f7a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sử dụng thiết bị: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import zipfile\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Kiểm tra thiết bị\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Sử dụng thiết bị: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TTybpC309JBi"
      },
      "outputs": [],
      "source": [
        "class VinaFoodDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.class_to_idx = {}\n",
        "\n",
        "        class_names = sorted(os.listdir(root_dir))\n",
        "        for i, class_name in enumerate(class_names):\n",
        "            class_path = os.path.join(root_dir, class_name)\n",
        "            if os.path.isdir(class_path):\n",
        "                self.class_to_idx[class_name] = i\n",
        "                for img_name in os.listdir(class_path):\n",
        "                    if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                        self.image_paths.append(os.path.join(class_path, img_name))\n",
        "                        self.labels.append(i)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vgvWGULe9fwB"
      },
      "outputs": [],
      "source": [
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    # transforms.RandomHorizontalFlip(),\n",
        "    # transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vAnnEyTV9jI7"
      },
      "outputs": [],
      "source": [
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9bUJ7m49kqX"
      },
      "outputs": [],
      "source": [
        "zip_path = '/content/drive/MyDrive/Colab_Notebooks/DS201/LAB_2/VinaFood21.zip'\n",
        "extract_path = '/content/drive/MyDrive/Colab_Notebooks/DS201/LAB_2/'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "base_data_dir = '/content/drive/MyDrive/Colab_Notebooks/DS201/LAB_2/VinaFood21'\n",
        "\n",
        "train_dir = os.path.join(base_data_dir, 'train')\n",
        "test_dir = os.path.join(base_data_dir, 'test')\n",
        "\n",
        "train_dataset = VinaFoodDataset(root_dir=train_dir, transform=train_transforms)\n",
        "test_dataset = VinaFoodDataset(root_dir=test_dir, transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apSbzq4W9mLw",
        "outputId": "7be34841-3485-4194-b48d-a050b1f5fec2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đã tìm thấy 21 lớp.\n",
            "Số lượng ảnh train: 10044\n",
            "Số lượng ảnh test: 6682\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(train_dataset.class_to_idx)\n",
        "print(f\"Đã tìm thấy {num_classes} lớp.\")\n",
        "print(f\"Số lượng ảnh train: {len(train_dataset)}\")\n",
        "print(f\"Số lượng ảnh test: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiDfkzDJ9opr",
        "outputId": "1596df0a-d53d-4ab0-d351-e2be90da63c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tạo DataLoader từ cấu trúc train/test thành công!\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "print(\"\\nTạo DataLoader từ cấu trúc train/test thành công!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFPWlvIA9qci"
      },
      "outputs": [],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, **kwargs):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
        "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.relu(self.batchnorm(self.conv(x)))\n",
        "\n",
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_channels, ch1x1, ch3x3_red, ch3x3, ch5x5_red, ch5x5, pool_proj):\n",
        "        super(Inception, self).__init__()\n",
        "        self.branch1 = ConvBlock(in_channels, ch1x1, kernel_size=1)\n",
        "        self.branch2 = nn.Sequential(\n",
        "            ConvBlock(in_channels, ch3x3_red, kernel_size=1),\n",
        "            ConvBlock(ch3x3_red, ch3x3, kernel_size=3, padding=1)\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            ConvBlock(in_channels, ch5x5_red, kernel_size=1),\n",
        "            ConvBlock(ch5x5_red, ch5x5, kernel_size=5, padding=2)\n",
        "        )\n",
        "        self.branch4 = nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            ConvBlock(in_channels, pool_proj, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        outputs = [self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)]\n",
        "        return torch.cat(outputs, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eGJCVpQ9sRo",
        "outputId": "3012a4d5-29d7-4495-95f8-e93071accbca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiến trúc GoogLeNet đã được tạo!\n"
          ]
        }
      ],
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self, in_channels=3, num_classes=21):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        self.conv1 = ConvBlock(in_channels, 64, kernel_size=7, stride=2, padding=3)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "        self.conv2 = ConvBlock(64, 64, kernel_size=1)\n",
        "        self.conv3 = ConvBlock(64, 192, kernel_size=3, padding=1)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "        self.inception3a = Inception(192, 64, 96, 128, 16, 32, 32)\n",
        "        self.inception3b = Inception(256, 128, 128, 192, 32, 96, 64)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "        self.inception4a = Inception(480, 192, 96, 208, 16, 48, 64)\n",
        "        self.inception4b = Inception(512, 160, 112, 224, 24, 64, 64)\n",
        "        self.inception4c = Inception(512, 128, 128, 256, 24, 64, 64)\n",
        "        self.inception4d = Inception(512, 112, 144, 288, 32, 64, 64)\n",
        "        self.inception4e = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True)\n",
        "        self.inception5a = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.inception5b = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.dropout = nn.Dropout(p=0.4)\n",
        "        self.fc1 = nn.Linear(1024, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x); x = self.maxpool1(x); x = self.conv2(x); x = self.conv3(x); x = self.maxpool2(x)\n",
        "        x = self.inception3a(x); x = self.inception3b(x); x = self.maxpool3(x)\n",
        "        x = self.inception4a(x); x = self.inception4b(x); x = self.inception4c(x); x = self.inception4d(x); x = self.inception4e(x); x = self.maxpool4(x)\n",
        "        x = self.inception5a(x); x = self.inception5b(x)\n",
        "        x = self.avgpool(x); x = x.reshape(x.shape[0], -1); x = self.dropout(x); x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "model = GoogLeNet(num_classes=num_classes).to(device)\n",
        "print(\"Kiến trúc GoogLeNet đã được tạo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXC-yJVn9uX6",
        "outputId": "875f7a6b-a384-45fd-89a5-3639d8c7611e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]:  98%|█████████▊| 308/314 [02:56<00:03,  1.84it/s, loss=2.47]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [1/10]: 100%|██████████| 314/314 [02:59<00:00,  1.75it/s, loss=3]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 1 Test Results ---\n",
            "Train Loss: 2.8033\n",
            "Accuracy: 0.1809 | Precision: 0.1500 | Recall: 0.1679 | F1-score: 0.1029\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [2/10]:  35%|███▌      | 110/314 [01:02<02:19,  1.46it/s, loss=2.66]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [2/10]: 100%|██████████| 314/314 [02:56<00:00,  1.78it/s, loss=2.55]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 2 Test Results ---\n",
            "Train Loss: 2.5487\n",
            "Accuracy: 0.2472 | Precision: 0.1941 | Recall: 0.2263 | F1-score: 0.1777\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [3/10]:  31%|███       | 97/314 [00:54<02:00,  1.80it/s, loss=2.37]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [3/10]: 100%|██████████| 314/314 [02:52<00:00,  1.82it/s, loss=2.13]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 3 Test Results ---\n",
            "Train Loss: 2.3773\n",
            "Accuracy: 0.2463 | Precision: 0.2089 | Recall: 0.2387 | F1-score: 0.1815\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [4/10]:  54%|█████▍    | 171/314 [01:37<01:39,  1.44it/s, loss=2.16]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [4/10]: 100%|██████████| 314/314 [02:54<00:00,  1.80it/s, loss=2.55]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 4 Test Results ---\n",
            "Train Loss: 2.1969\n",
            "Accuracy: 0.3155 | Precision: 0.3042 | Recall: 0.2795 | F1-score: 0.2499\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [5/10]:  74%|███████▎  | 231/314 [02:08<00:46,  1.80it/s, loss=1.74]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [5/10]: 100%|██████████| 314/314 [02:54<00:00,  1.80it/s, loss=2.4]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 5 Test Results ---\n",
            "Train Loss: 2.0744\n",
            "Accuracy: 0.3505 | Precision: 0.3474 | Recall: 0.3115 | F1-score: 0.2973\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [6/10]:  62%|██████▏   | 195/314 [01:46<01:03,  1.88it/s, loss=2.01]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [6/10]: 100%|██████████| 314/314 [02:52<00:00,  1.82it/s, loss=1.99]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 6 Test Results ---\n",
            "Train Loss: 1.9483\n",
            "Accuracy: 0.3463 | Precision: 0.3272 | Recall: 0.3177 | F1-score: 0.3070\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [7/10]:  78%|███████▊  | 246/314 [02:15<00:48,  1.39it/s, loss=1.75]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [7/10]: 100%|██████████| 314/314 [02:51<00:00,  1.83it/s, loss=1.84]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 7 Test Results ---\n",
            "Train Loss: 1.8270\n",
            "Accuracy: 0.3466 | Precision: 0.3793 | Recall: 0.3310 | F1-score: 0.3068\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [8/10]:  28%|██▊       | 87/314 [00:47<01:30,  2.50it/s, loss=1.68]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [8/10]: 100%|██████████| 314/314 [02:50<00:00,  1.84it/s, loss=2.05]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 8 Test Results ---\n",
            "Train Loss: 1.7250\n",
            "Accuracy: 0.3894 | Precision: 0.4154 | Recall: 0.3664 | F1-score: 0.3482\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [9/10]:  54%|█████▎    | 168/314 [01:31<01:14,  1.96it/s, loss=1.34]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [9/10]: 100%|██████████| 314/314 [02:49<00:00,  1.85it/s, loss=1.55]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 9 Test Results ---\n",
            "Train Loss: 1.6194\n",
            "Accuracy: 0.4056 | Precision: 0.4071 | Recall: 0.3960 | F1-score: 0.3782\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [10/10]:   1%|          | 2/314 [00:01<04:00,  1.30it/s, loss=1.44]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [10/10]: 100%|██████████| 314/314 [02:49<00:00,  1.85it/s, loss=1.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 10 Test Results ---\n",
            "Train Loss: 1.4979\n",
            "Accuracy: 0.4045 | Precision: 0.4365 | Recall: 0.3861 | F1-score: 0.3609\n",
            "\n",
            "Hoàn thành quá trình huấn luyện!\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # --- Training ---\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    train_loop = tqdm(train_loader, total=len(train_loader), leave=True)\n",
        "    for images, labels in train_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        train_loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # --- Evaluation on Test Set ---\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        # Đánh giá trên test_loader\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\n--- Epoch {epoch+1} Test Results ---\")\n",
        "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1:.4f}\\n\")\n",
        "\n",
        "print(\"Hoàn thành quá trình huấn luyện!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_e7C7BlAqpx"
      },
      "source": [
        "### Bài 3: Xây dựng mô hình ResNet-18, đánh giá mô hình ResNet-18 trên bộ dữ liệu VinaFood21 sử dụng các độ đo precision, recall, và F1 (Sử dụng Adam làm optimizer). Lưu ý, giữa các block Residual-Connection có một lớp Max Pooling (kernel = 3, stride = 2, paddding = 0)\n",
        "\n",
        "**ResNet Block**\n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "**ResNet**\n",
        "\n",
        "![image-2.png](attachment:image-2.png)\n",
        "\n",
        "**ResNet-18 Parameter**\n",
        "![image-4.png](attachment:image-4.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge8kUFdH92us"
      },
      "outputs": [],
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "\n",
        "        # Luồng chính (main path)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        # Luồng phụ (shortcut path) để cộng trực tiếp\n",
        "        self.shortcut = nn.Sequential()\n",
        "        # Nếu số kênh đầu vào và đầu ra khác nhau, ta cần một lớp 1x1 Conv\n",
        "        # để biến đổi shortcut cho phù hợp về kích thước.\n",
        "        if in_channels != out_channels:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Lưu lại đầu vào cho shortcut connection\n",
        "        shortcut_out = self.shortcut(x)\n",
        "\n",
        "        # Cho dữ liệu đi qua luồng chính\n",
        "        main_out = self.relu(self.bn1(self.conv1(x)))\n",
        "        main_out = self.bn2(self.conv2(main_out))\n",
        "\n",
        "        # Cộng luồng chính và luồng phụ, sau đó qua ReLU\n",
        "        out = self.relu(main_out + shortcut_out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tR03zHG994cQ",
        "outputId": "1e5fef72-7806-4b23-a698-054649cde80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kiến trúc ResNet-18 đã được tạo!\n",
            "ResNet18(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool_stem): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (custom_maxpool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=21, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class ResNet18(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=21):\n",
        "        super(ResNet18, self).__init__()\n",
        "        self.in_channels = 64\n",
        "\n",
        "        # 1. Lớp đầu vào (Stem)\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool_stem = nn.MaxPool2d(kernel_size=3, stride=2, padding=1) # Maxpool chuẩn\n",
        "\n",
        "        # 2. Các khối Residual\n",
        "        # Dựa trên bảng tham số, ResNet-18 có cấu hình [2, 2, 2, 2]\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0])\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1])\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2])\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3])\n",
        "\n",
        "        # Lớp Max Pooling đặc biệt theo yêu cầu (k=3, s=2, p=0)\n",
        "        self.custom_maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n",
        "\n",
        "        # 3. Lớp cuối (Classifier)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, out_channels, num_blocks):\n",
        "        layers = []\n",
        "        # Block đầu tiên của mỗi layer có thể thay đổi số kênh\n",
        "        layers.append(block(self.in_channels, out_channels))\n",
        "        self.in_channels = out_channels\n",
        "        # Các block còn lại giữ nguyên số kênh\n",
        "        for _ in range(1, num_blocks):\n",
        "            layers.append(block(self.in_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Stem\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.maxpool_stem(x)\n",
        "\n",
        "        # Các khối Residual và lớp Max Pooling đặc biệt\n",
        "        x = self.layer1(x)\n",
        "        x = self.custom_maxpool(x)\n",
        "\n",
        "        x = self.layer2(x)\n",
        "        x = self.custom_maxpool(x)\n",
        "\n",
        "        x = self.layer3(x)\n",
        "        x = self.custom_maxpool(x)\n",
        "\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        # Classifier\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1) # Flatten\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Khởi tạo model ResNet-18\n",
        "model = ResNet18(ResidualBlock, [2, 2, 2, 2], num_classes=num_classes).to(device)\n",
        "print(\"Kiến trúc ResNet-18 đã được tạo!\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvgXMFlm96ug",
        "outputId": "42946c8c-0029-4b3d-ed16-541c457f0f9e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [1/10]:  24%|██▍       | 76/314 [00:41<01:36,  2.46it/s, loss=2.71]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [1/10]: 100%|██████████| 314/314 [02:45<00:00,  1.89it/s, loss=2.36]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 1 Test Results ---\n",
            "Train Loss: 2.5134\n",
            "Accuracy: 0.2749 | Precision: 0.2657 | Recall: 0.2659 | F1-score: 0.2272\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [2/10]:  96%|█████████▌| 300/314 [02:36<00:06,  2.15it/s, loss=2.05]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [2/10]: 100%|██████████| 314/314 [02:43<00:00,  1.91it/s, loss=2.23]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 2 Test Results ---\n",
            "Train Loss: 2.1158\n",
            "Accuracy: 0.2622 | Precision: 0.3572 | Recall: 0.2687 | F1-score: 0.2318\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [3/10]:  13%|█▎        | 41/314 [00:21<02:05,  2.18it/s, loss=2]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [3/10]: 100%|██████████| 314/314 [02:44<00:00,  1.91it/s, loss=1.81]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 3 Test Results ---\n",
            "Train Loss: 1.8570\n",
            "Accuracy: 0.3797 | Precision: 0.4191 | Recall: 0.3565 | F1-score: 0.3393\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [4/10]:   1%|▏         | 4/314 [00:05<05:33,  1.08s/it, loss=1.43]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [4/10]: 100%|██████████| 314/314 [03:35<00:00,  1.46it/s, loss=1.65]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 4 Test Results ---\n",
            "Train Loss: 1.6723\n",
            "Accuracy: 0.4033 | Precision: 0.4655 | Recall: 0.4007 | F1-score: 0.3909\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [5/10]:  20%|█▉        | 62/314 [00:39<01:57,  2.15it/s, loss=1.71]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [5/10]: 100%|██████████| 314/314 [02:54<00:00,  1.80it/s, loss=1.49]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 5 Test Results ---\n",
            "Train Loss: 1.5086\n",
            "Accuracy: 0.4024 | Precision: 0.4770 | Recall: 0.4076 | F1-score: 0.4032\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [6/10]:  65%|██████▍   | 203/314 [01:52<00:45,  2.45it/s, loss=1.69]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [6/10]: 100%|██████████| 314/314 [02:51<00:00,  1.83it/s, loss=0.974]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 6 Test Results ---\n",
            "Train Loss: 1.3560\n",
            "Accuracy: 0.4886 | Precision: 0.4924 | Recall: 0.4871 | F1-score: 0.4715\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [7/10]:  71%|███████   | 223/314 [01:58<00:37,  2.45it/s, loss=1.13]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [7/10]: 100%|██████████| 314/314 [02:46<00:00,  1.88it/s, loss=0.886]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 7 Test Results ---\n",
            "Train Loss: 1.2389\n",
            "Accuracy: 0.4954 | Precision: 0.5309 | Recall: 0.4911 | F1-score: 0.4758\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [8/10]:  76%|███████▌  | 239/314 [02:08<00:40,  1.84it/s, loss=0.962]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [8/10]: 100%|██████████| 314/314 [02:46<00:00,  1.88it/s, loss=1.25]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 8 Test Results ---\n",
            "Train Loss: 1.0961\n",
            "Accuracy: 0.4620 | Precision: 0.5280 | Recall: 0.4465 | F1-score: 0.4427\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [9/10]:  41%|████      | 128/314 [01:08<01:26,  2.15it/s, loss=0.899]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [9/10]: 100%|██████████| 314/314 [02:47<00:00,  1.87it/s, loss=1.1]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 9 Test Results ---\n",
            "Train Loss: 0.9871\n",
            "Accuracy: 0.5262 | Precision: 0.5756 | Recall: 0.4961 | F1-score: 0.4957\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch [10/10]:  98%|█████████▊| 307/314 [02:42<00:03,  2.29it/s, loss=0.937]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch [10/10]: 100%|██████████| 314/314 [02:47<00:00,  1.87it/s, loss=0.739]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Epoch 10 Test Results ---\n",
            "Train Loss: 0.8576\n",
            "Accuracy: 0.5109 | Precision: 0.5849 | Recall: 0.5286 | F1-score: 0.5104\n",
            "\n",
            "Hoàn thành quá trình huấn luyện!\n"
          ]
        }
      ],
      "source": [
        "# --- Thiết lập quá trình huấn luyện ---\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "num_epochs = 10\n",
        "\n",
        "# --- Vòng lặp huấn luyện và đánh giá ---\n",
        "for epoch in range(num_epochs):\n",
        "    # --- Training ---\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    train_loop = tqdm(train_loader, total=len(train_loader), leave=True)\n",
        "    for images, labels in train_loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        train_loop.set_description(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
        "        train_loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    # --- Evaluation on Test Set ---\n",
        "    model.eval()\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "\n",
        "    print(f\"\\n--- Epoch {epoch+1} Test Results ---\")\n",
        "    print(f\"Train Loss: {running_loss/len(train_loader):.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | F1-score: {f1:.4f}\\n\")\n",
        "\n",
        "print(\"Hoàn thành quá trình huấn luyện!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXRiw8toAqpy"
      },
      "source": [
        "### Bài 4: Sử dụng pretrained ResNet50 từ HuggingFace để fine-tune trên bộ dữ liệu VinaFood21."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W48xatxQIoiM",
        "outputId": "f273cec6-8502-4b6b-afae-bc748f7dd7f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Đang sử dụng thiết bị: cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "from tqdm import tqdm\n",
        "from transformers import ResNetForImageClassification\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Đang sử dụng thiết bị: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ld_fIi-VK4XD"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                         std=[0.229, 0.224, 0.225]),\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tsq6rc12LA55",
        "outputId": "6f2db7f3-f511-481f-f256-01c1b62444a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Số ảnh train: 10044 | test: 6683\n"
          ]
        }
      ],
      "source": [
        "base_data_dir = '/content/drive/MyDrive/VinaFood21'\n",
        "train_dir = os.path.join(base_data_dir, 'train')\n",
        "test_dir = os.path.join(base_data_dir, 'test')\n",
        "\n",
        "train_dataset = VinaFoodDataset(root_dir=train_dir, transform=train_transforms)\n",
        "test_dataset = VinaFoodDataset(root_dir=test_dir, transform=test_transforms)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"Số ảnh train: {len(train_dataset)} | test: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ZU4E_CVtLToh"
      },
      "outputs": [],
      "source": [
        "class PretrainedResnet(nn.Module):\n",
        "    def __init__(self, num_classes=21):\n",
        "        super().__init__()\n",
        "        basemodel = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
        "        self.resnet = basemodel.resnet\n",
        "        self.classifier = nn.Linear(in_features=2048, out_features=num_classes, bias=True)\n",
        "\n",
        "    def forward(self, images: torch.Tensor):\n",
        "        features = self.resnet(images).pooler_output\n",
        "        features = features.squeeze(-1).squeeze(-1)\n",
        "        logits = self.classifier(features)\n",
        "        return logits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhIvHeIhLWa5",
        "outputId": "93e63b45-d3e3-4ece-abe0-28e9ed0f532e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Train:  59%|█████▉    | 186/314 [21:49<14:00,  6.57s/it]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 1/10 - Train: 100%|██████████| 314/314 [37:07<00:00,  7.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 2.6690 | Train Acc: 0.2209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 - Test: 100%|██████████| 209/209 [26:10<00:00,  7.51s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 2.0756 | Test Acc: 0.4666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 - Train:  96%|█████████▌| 301/314 [03:07<00:08,  1.47it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 2/10 - Train: 100%|██████████| 314/314 [03:14<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 1.3343 | Train Acc: 0.6557\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 - Test: 100%|██████████| 209/209 [01:57<00:00,  1.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.9644 | Test Acc: 0.7196\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 - Train:  57%|█████▋    | 180/314 [01:52<01:19,  1.69it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 3/10 - Train: 100%|██████████| 314/314 [03:15<00:00,  1.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.6759 | Train Acc: 0.8053\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 - Test: 100%|██████████| 209/209 [01:54<00:00,  1.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.7375 | Test Acc: 0.7717\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 - Train:  79%|███████▉  | 248/314 [02:31<00:34,  1.94it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 4/10 - Train: 100%|██████████| 314/314 [03:12<00:00,  1.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.4194 | Train Acc: 0.8779\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 - Test: 100%|██████████| 209/209 [01:54<00:00,  1.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.6424 | Test Acc: 0.8041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 - Train:  60%|██████    | 189/314 [01:54<01:07,  1.84it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 5/10 - Train: 100%|██████████| 314/314 [03:10<00:00,  1.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.2703 | Train Acc: 0.9241\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 - Test: 100%|██████████| 209/209 [01:54<00:00,  1.83it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.5930 | Test Acc: 0.8157\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 - Train:  74%|███████▍  | 232/314 [02:21<00:40,  2.00it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 6/10 - Train: 100%|██████████| 314/314 [03:12<00:00,  1.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1711 | Train Acc: 0.9549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 - Test: 100%|██████████| 209/209 [01:55<00:00,  1.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.5550 | Test Acc: 0.8314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 - Train:  95%|█████████▍| 297/314 [03:02<00:09,  1.70it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 7/10 - Train: 100%|██████████| 314/314 [03:11<00:00,  1.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.1060 | Train Acc: 0.9745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 - Test: 100%|██████████| 209/209 [01:54<00:00,  1.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.5662 | Test Acc: 0.8330\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 - Train:  89%|████████▉ | 279/314 [02:50<00:20,  1.69it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 8/10 - Train: 100%|██████████| 314/314 [03:11<00:00,  1.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0758 | Train Acc: 0.9846\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 - Test: 100%|██████████| 209/209 [01:51<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.5651 | Test Acc: 0.8332\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 - Train:  54%|█████▍    | 170/314 [01:41<01:31,  1.58it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 9/10 - Train: 100%|██████████| 314/314 [03:06<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0514 | Train Acc: 0.9898\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 - Test: 100%|██████████| 209/209 [01:50<00:00,  1.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.5834 | Test Acc: 0.8367\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 - Train:  64%|██████▍   | 201/314 [02:00<01:06,  1.69it/s]/usr/local/lib/python3.12/dist-packages/PIL/Image.py:1047: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Epoch 10/10 - Train: 100%|██████████| 314/314 [03:07<00:00,  1.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: 0.0425 | Train Acc: 0.9913\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 - Test: 100%|██████████| 209/209 [01:50<00:00,  1.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.5929 | Test Acc: 0.8348\n",
            "Fine-tuning hoàn tất!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = PretrainedResnet(num_classes=21).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "EPOCHS = 10\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Train\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    print(f\"Train Loss: {train_loss/len(train_loader):.4f} | Train Acc: {acc:.4f}\")\n",
        "\n",
        "    # Đánh giá trên tập test\n",
        "    model.eval()\n",
        "    test_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} - Test\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    test_acc = correct / total\n",
        "    print(f\"Test Loss: {test_loss/len(test_loader):.4f} | Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "print(\"Fine-tuning hoàn tất!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
